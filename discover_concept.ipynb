{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe245d6",
   "metadata": {},
   "source": [
    "This script runs the whole ACE method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f33d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate VRX\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d1af57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tcav import utils\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from src import ace_helpers\n",
    "from src.ace import ConceptDiscovery\n",
    "import argparse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2256c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet label for each class\n",
    "class_dict = {\n",
    "    'ambulance': 'n02701002',\n",
    "    'fire_engine': 'n03345487',\n",
    "    'school_bus': 'n04146614',\n",
    "    'beach_wagon': 'n02814533',\n",
    "    'jeep': 'n03594945',\n",
    "    'recreational_vehicle': 'n04065272',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22f2ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # for each class, extract the concept and store them in corresponding folder\n",
    "    # target_class,folder e.g. ambulance,n02701002\n",
    "    for target_class, folder in class_dict.items():\n",
    "        \n",
    "        print('start discovering concept of {}'.format(target_class))\n",
    "        random_concept = 'random_discovery'  # Random concept for statistical testing\n",
    "        sess = utils.create_session()\n",
    "\n",
    "        # Create tcav model instance\n",
    "        if args.model_to_run != 'Xception':\n",
    "            mymodel = ace_helpers.make_model(sess, args.model_to_run, args.model_path, args.labels_path)\n",
    "        else:\n",
    "            if args.gradcam_layer:\n",
    "                mymodel = ace_helpers.make_model(None, args.model_to_run, None, args.labels_path, gradcam_layer=args.gradcam_layer)\n",
    "            else:\n",
    "                mymodel = ace_helpers.make_model(None, args.model_to_run, None, args.labels_path)\n",
    "\n",
    "        ###### related DIRs on CNS to store results #######\n",
    "        '''we change the folder to show the detected feature form grad-cam'''\n",
    "        \n",
    "        # Extract bottleneck layer from args or mymodel\n",
    "        if args.bottlenecks:\n",
    "            bottlenecks = args.bottlenecks.split(',')\n",
    "        else:\n",
    "            bottlenecks = mymodel.find_target_layer()\n",
    "\n",
    "        # Create corresponding paths to store results\n",
    "        discovered_concepts_dir = os.path.join(args.working_dir, 'output', target_class, 'concepts/')\n",
    "        results_dir = os.path.join(args.working_dir, 'output', target_class, 'results/')\n",
    "        cavs_dir = os.path.join(args.working_dir, 'output', target_class, 'cavs/')\n",
    "        activations_dir = os.path.join(args.working_dir, 'output', target_class, 'acts/')\n",
    "        results_summaries_dir = os.path.join(args.working_dir, 'output', target_class, 'results_summaries/')\n",
    "\n",
    "        # Create directories to store results\n",
    "        if not os.path.exists(discovered_concepts_dir):\n",
    "            os.makedirs(discovered_concepts_dir)\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "        if not os.path.exists(cavs_dir):\n",
    "            os.makedirs(cavs_dir)\n",
    "        if not os.path.exists(activations_dir):\n",
    "            os.makedirs(activations_dir)\n",
    "        if not os.path.exists(results_summaries_dir):\n",
    "            os.makedirs(results_summaries_dir)\n",
    "\n",
    "        # Creating the ConceptDiscovery (ACE) class instance\n",
    "        cd = ConceptDiscovery(\n",
    "            mymodel,\n",
    "            # args.target_class,\n",
    "            target_class, # we run a for loop\n",
    "            random_concept,\n",
    "            bottlenecks,\n",
    "            sess,\n",
    "            args.source_dir,\n",
    "            activations_dir,\n",
    "            cavs_dir,\n",
    "            num_random_exp=args.num_random_exp,\n",
    "            channel_mean=True,\n",
    "            max_imgs=args.max_imgs,\n",
    "            min_imgs=args.min_imgs,\n",
    "            num_discovery_imgs=args.max_imgs,\n",
    "            num_workers=args.num_parallel_workers)\n",
    "        \n",
    "        # Creating the dataset of image patches with 3 different resolutions\n",
    "        print(datetime.datetime.now(), 'Creating the dataset of image patches of {}...'.format(target_class))\n",
    "        cd.create_patches(param_dict={'n_segments': [15, 50, 80]}, gradcam=args.use_gradcam, keep_percent=args.keep_percent)\n",
    "        '''for X-ray, we need larger patch'''\n",
    "\n",
    "        # Saving the concept discovery target class images\n",
    "        image_dir = os.path.join(discovered_concepts_dir, 'images')\n",
    "        tf.gfile.MakeDirs(image_dir)\n",
    "        ace_helpers.save_images(image_dir, (cd.discovery_images * 256).astype(np.uint8))\n",
    "        \n",
    "        # Discovering Concepts and store in cd\n",
    "        print(datetime.datetime.now(), 'Discovering concepts of {}...'.format(target_class))\n",
    "        cd.discover_concepts(method='KM', param_dicts={'n_clusters': 25})\n",
    "\n",
    "        # Free memory\n",
    "        del cd.dataset  \n",
    "        del cd.image_numbers\n",
    "        del cd.patches\n",
    "\n",
    "        #Save the concept information as dict txt\n",
    "        dict_name = cd.dic\n",
    "        dict_save_path = os.path.join(discovered_concepts_dir, 'all_concept_dict_X.txt')\n",
    "        f = open(dict_save_path, 'wb')\n",
    "        pickle.dump(dict_name, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "\n",
    "        # Save discovered concept images (resized and original sized)\n",
    "        ace_helpers.save_concepts(cd, discovered_concepts_dir)\n",
    "        \n",
    "        # Calculating CAVs and TCAV scores\n",
    "        print(datetime.datetime.now(), 'Calculating CAVs and TCAV scores of {}...'.format(target_class))\n",
    "        cav_accuraciess = cd.cavs(min_acc=0.0)\n",
    "        scores = cd.tcavs(test=False)\n",
    "        ace_helpers.save_ace_report(cd, cav_accuraciess, scores, results_summaries_dir + 'ace_results.txt')\n",
    "        \n",
    "        # Plot examples of discovered concepts\n",
    "        print(datetime.datetime.now(), 'Plotting examples of discovered concepts of {}...'.format(target_class))\n",
    "        for bn in cd.bottlenecks:\n",
    "            ace_helpers.plot_concepts(cd, bn, 10, address=results_dir)\n",
    "            # Delete concepts that don't pass statistical testing\n",
    "            cd.test_and_remove_concepts(scores)\n",
    "        print('finish discovering concept of {}'.format(target_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "041b4874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments(argv):\n",
    "    '''Parses the arguments passed to the run.py script.'''\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--source_dir', type=str, default='source',\n",
    "      help='''Directory where the network's classes image folders and random concept folders are saved.''')\n",
    "    parser.add_argument('--working_dir', type=str,\n",
    "      help='Directory to save the results.', default='result')\n",
    "\n",
    "    parser.add_argument('--use_gradcam', type=bool,\n",
    "      help='''Whether use gradcam to filter the patches.''', default=True)\n",
    "    parser.add_argument('--gradcam_layer', type=str, help='''which ;ayer to use gradcam.''', default='')\n",
    "    parser.add_argument('--keep_percent', type=int,\n",
    "      help='''the percentage of gradcam to filter the mask.''', default=50)\n",
    "\n",
    "    parser.add_argument('--model_to_run', type=str,\n",
    "      help='The name of the model.', default='Xception')\n",
    "    parser.add_argument('--model_path', type=str,\n",
    "      help='Path to model checkpoints.', default='')\n",
    "    parser.add_argument('--labels_path', type=str,\n",
    "      help='Path to model checkpoints.', default='src/Xception_labels.json')\n",
    "\n",
    "    '''Because ACE only have Imagenet classes, so you should copy and past Chexpert\n",
    "    images into zebra'''\n",
    "    parser.add_argument('--target_class', type=str,\n",
    "      help='The name of the target class to be interpreted,zebra, ambulance', default='all')\n",
    "    parser.add_argument('--bottlenecks', type=str,\n",
    "      help='Names of the target layers of the network (comma separated)',\n",
    "                      default='')\n",
    "    parser.add_argument('--num_random_exp', type=int,\n",
    "      help=\"Number of random experiments used for statistical testing, etc\",\n",
    "                      default=20)\n",
    "    parser.add_argument('--max_imgs', type=int,\n",
    "      help=\"Maximum number of images in a discovered concept\",\n",
    "                      default=50)\n",
    "    parser.add_argument('--min_imgs', type=int,\n",
    "      help=\"Minimum number of images in a discovered concept\",\n",
    "                      default=40)\n",
    "    parser.add_argument('--num_parallel_workers', type=int,\n",
    "      help=\"Number of parallel jobs.\",\n",
    "                      default=0)\n",
    "    return parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfbbe7-1c36-4a9c-8548-39dba5342d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
