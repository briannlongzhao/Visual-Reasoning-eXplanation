{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8199f3d2-90d5-49b7-9559-3648984b512d",
   "metadata": {},
   "source": [
    "ACE library.\n",
    "\n",
    "Library for discovering and testing concept activation vectors. It contains\n",
    "ConceptDiscovery class that is able to discover the concepts belonging to one\n",
    "of the possible ResNet_pytorch labels of the ResNet_pytorch task of a network\n",
    "and calculate each concept's TCAV score.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd2df86-bc67-4049-92ca-66da9d8d1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7261292d-20b0-422a-a0bb-c36f49e330c0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\envs\\VRX\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-accecd75e3f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcurdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mace_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\U\\r\\Visual-Reasoning-eXplanation\\src\\ace_helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_Xception\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradcam\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTARGET_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "import scipy.stats as stats\n",
    "import skimage.segmentation as segmentation\n",
    "import sklearn.cluster as cluster\n",
    "import sklearn.metrics.pairwise as metrics\n",
    "from tcav import cav\n",
    "curdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0,curdir)\n",
    "from ace_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddcd4e0-ab16-4194-9640-0bed0a392a88",
   "metadata": {},
   "source": [
    "Discovering and testing concepts of a class.\n",
    "\n",
    "For a trained network, it first discovers the concepts as areas of the iamges in the class and then calculates the TCAV score of each concept. It is also able to transform images from pixel space into concept space.\n",
    "\n",
    "Runs concept discovery for a given class in a trained model.\n",
    "\n",
    "For a trained ResNet_pytorch model, the ConceptDiscovery class first performs unsupervised concept discovery using examples of one of the classes in the network.\n",
    "\n",
    "Args:\\\n",
    "    model: A trained ResNet_pytorch model on which we run the concept discovery algorithm\\\n",
    "    target_class: Name of the one of the classes of the network\\\n",
    "    random_concept: A concept made of random images (used for statistical test) e.g. \"random500_199\"\\\n",
    "    bottlenecks: a list of bottleneck layers of the model for which the cocept discovery stage is performed\\\n",
    "    sess: Model's tensorflow session\\\n",
    "    source_dir: This directory that contains folders with images of network's classes.\\\n",
    "    activation_dir: directory to save computed activations\\\n",
    "    cav_dir: directory to save CAVs of discovered and random concepts\\\n",
    "    num_random_exp: Number of random counterparts used for calculating several CAVs and TCAVs for each concept (to make statistical testing possible.)\\\n",
    "    channel_mean: If true, for the unsupervised concept discovery the bottleneck activations are averaged over channels instead of using the whole acivation vector (reducing dimensionality)\\\n",
    "    max_imgs: maximum number of images in a discovered concept\\\n",
    "    min_imgs : minimum number of images in a discovered concept for the concept to be accepted\\\n",
    "    num_discovery_imgs: Number of images used for concept discovery. If None, will use max_imgs instead.\\\n",
    "    num_workers: if greater than zero, runs methods in parallel with num_workers parallel threads. If 0, no method is run in parallel threads.\\\n",
    "    average_image_value: The average value used for mean subtraction in the nework's preprocessing stage.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eed5863-9d13-4c2f-955b-adea8049cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptDiscovery(object):\n",
    "    def __init__(self,\n",
    "               model,\n",
    "               target_class,\n",
    "               random_concept,\n",
    "               bottlenecks,\n",
    "               sess,\n",
    "               source_dir,\n",
    "               activation_dir,\n",
    "               cav_dir,\n",
    "               num_random_exp=2,\n",
    "               channel_mean=True,\n",
    "               max_imgs=40,\n",
    "               min_imgs=20,\n",
    "               num_discovery_imgs=40,\n",
    "               num_workers=20,\n",
    "               average_image_value=117\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.sess = sess\n",
    "        self.target_class = target_class\n",
    "        self.num_random_exp = num_random_exp\n",
    "        if isinstance(bottlenecks, str):\n",
    "            bottlenecks = [bottlenecks]\n",
    "        self.bottlenecks = bottlenecks\n",
    "        self.source_dir = source_dir\n",
    "        self.activation_dir = activation_dir\n",
    "        self.cav_dir = cav_dir\n",
    "        self.channel_mean = channel_mean\n",
    "        self.random_concept = random_concept\n",
    "        self.image_shape = model.get_image_shape()[:2]\n",
    "        self.max_imgs = max_imgs\n",
    "        self.min_imgs = min_imgs\n",
    "        if num_discovery_imgs is None:\n",
    "            num_discovery_imgs = max_imgs\n",
    "        self.num_discovery_imgs = num_discovery_imgs\n",
    "        self.num_workers = num_workers\n",
    "        self.average_image_value = average_image_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc0984-8fbc-4f06-a341-0145fb881edf",
   "metadata": {},
   "source": [
    "Loads all colored images of a concept.\n",
    "\n",
    "Args:\\\n",
    "    concept: The name of the concept to be loaded\\\n",
    "    max_imgs: maximum number of images to be loaded\n",
    "\n",
    "Returns:\\\n",
    "Images of the desired concept or class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "531c30f8-db8e-48d8-814a-9b425e20a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to ConceptDiscovery\n",
    "def load_concept_imgs(self, concept, max_imgs=1000, compute_tcav = False):\n",
    "    if compute_tcav:\n",
    "        concept_dir = os.path.join(self.source_dir, concept+'_50')\n",
    "    else:\n",
    "        concept_dir = os.path.join(self.source_dir, concept)\n",
    "\n",
    "    img_paths = [\n",
    "        os.path.join(concept_dir, d)\n",
    "        for d in tf.gfile.ListDirectory(concept_dir)\n",
    "    ]\n",
    "    return load_images_from_files(\n",
    "        img_paths,\n",
    "        max_imgs=max_imgs,\n",
    "        return_filenames=False,\n",
    "        do_shuffle=False,\n",
    "        run_parallel=(self.num_workers > 0),\n",
    "        shape=(self.image_shape),\n",
    "        num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74682477-fd13-42fd-8fc5-e7a6cb417895",
   "metadata": {},
   "source": [
    "Creates a set of image patches using superpixel methods.\n",
    "\n",
    "This method takes in the concept discovery images and transforms it to adataset made of the patches of those images.\n",
    "\n",
    "Args:\\\n",
    "    method: The superpixel method used for creating image patches. One of 'slic', 'watershed', 'quickshift', 'felzenszwalb'.\\\n",
    "    discovery_images: Images used for creating patches. If None, the images in the target class folder are used.\\\n",
    "    param_dict: Contains parameters of the superpixel method used in the form of {'param1':[a,b,...], 'param2':[z,y,x,...], ...}. For instance {'n_segments':[15,50,80], 'compactness':[10,10,10]} for slic method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44f9ae7-03d3-41ac-83a3-4dd6d7a75187",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to ConceptDiscovery\n",
    "def create_patches(self, method='slic', discovery_images=None, param_dict=None, gradcam=False, keep_percent=80):\n",
    "    if param_dict is None:\n",
    "        param_dict = {}\n",
    "    dataset, image_numbers, patches = [], [], []\n",
    "    if discovery_images is None:\n",
    "        raw_imgs = self.load_concept_imgs(self.target_class, self.num_discovery_imgs, compute_tcav=True)\n",
    "        self.discovery_images = raw_imgs\n",
    "    else:\n",
    "        self.discovery_images = discovery_images\n",
    "    if self.num_workers:\n",
    "        pool = multiprocessing.Pool(self.num_workers)\n",
    "        if gradcam:\n",
    "            outputs = pool.map(lambda img: self._return_gradcam_superpixels(img, method, param_dict, keep_percent), self.discovery_images)\n",
    "        else:\n",
    "            outputs = pool.map(lambda img: self._return_superpixels(img, method, param_dict), self.discovery_images)\n",
    "        for fn, sp_outputs in enumerate(outputs):\n",
    "            image_superpixels, image_patches = sp_outputs\n",
    "            for superpixel, patch in zip(image_superpixels, image_patches):\n",
    "                dataset.append(superpixel)\n",
    "                patches.append(patch)\n",
    "                image_numbers.append(fn)\n",
    "    else:\n",
    "      for fn, img in enumerate(self.discovery_images):\n",
    "        if gradcam:\n",
    "          image_superpixels, image_patches = self._return_gradcam_superpixels(\n",
    "            img, method, param_dict, keep_percent)\n",
    "        else:\n",
    "          image_superpixels, image_patches = self._return_superpixels(\n",
    "              img, method, param_dict)\n",
    "        for superpixel, patch in zip(image_superpixels, image_patches):\n",
    "          dataset.append(superpixel)\n",
    "          patches.append(patch)\n",
    "          image_numbers.append(fn)\n",
    "    self.dataset, self.image_numbers, self.patches = np.array(dataset), np.array(image_numbers), np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71084b91-5aa4-4f7a-b954-3f59b815ba17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
