{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc5d76e-fe6c-42b4-9535-cf9d1b8ee1f0",
   "metadata": {},
   "source": [
    "This script train the graph reasoning algorithm use detected concept for XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c97ca8-1289-4c92-bc56-313c86a47720",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate VRX\n",
    "import jdc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e43fc87-74a9-402a-8a2e-d4801fd1e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from src.image_folder import make_dataset\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as f\n",
    "from torch.nn import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "from torch_geometric.nn import GraphConv\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, OptPairTensor, Adj, Size\n",
    "import argparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc9d60-7cd6-4362-987b-4c7bcf192c86",
   "metadata": {},
   "source": [
    "create training dataset, InMemoryDataset should be used if the whole dataset fits into CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c2f9d2-750a-4161-81e8-92620ca4828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VR_graph(InMemoryDataset): \n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        self.root = root\n",
    "        super(VR_graph, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices, self.XAI_act = torch.load(self.processed_file_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc872eb5-d5e2-4c14-b38a-c9b498e3e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "@property\n",
    "def raw_file_names(self):\n",
    "    return []\n",
    "\n",
    "@property\n",
    "def processed_file_names(self):\n",
    "    return [os.path.join(self.root, 'vec2graph', 'Xception_XAI_graph_training.dataset')]\n",
    "\n",
    "def download(self):\n",
    "        pass\n",
    "'''useful for utils'''\n",
    "\n",
    "def read_txt(self, path):\n",
    "    f = open(path, 'r')\n",
    "    b = f.read()\n",
    "    pos_graph = eval(b)\n",
    "    f.close()\n",
    "    return pos_graph\n",
    "\n",
    "def choose_graph(self, list_mix):\n",
    "    while 1:\n",
    "        pos_graph_path = random.choice(list_mix)\n",
    "        if '_graph.' in pos_graph_path:\n",
    "            return pos_graph_path\n",
    "'''process for contrastive loss'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501f4ae-3117-46b7-a9ca-d76ac7d0130b",
   "metadata": {},
   "source": [
    "Get graph data list, where graph data is a torch_geometric data reprentation of a graph.\\\n",
    "For each class, generate 2 positive and 4 negative graphs [+1,-1,-1, +1,-1,-1]\n",
    "graph_data_list has 1*18 graph representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6405b9ab-95c3-4f3e-b9ec-ac55cede1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "def _get_3class_eij(self):\n",
    "    class_list = ['fire_engine', 'ambulance', 'school_bus']\n",
    "    graph_data_list = []\n",
    "    \n",
    "    # for (label=[0,1,2], cate=[class_list])\n",
    "    for label, cate in enumerate(class_list): # 3 category, 6 graph for each class [+1,-1,-1, +1,-1,-1]\n",
    "        \n",
    "        # pos_class_g is an array of paths of training images of a given class\n",
    "        pos_class_path = os.path.join('./result/img2vec/', 'train', cate, cate) # real + eij\n",
    "        pos_class_g = make_dataset(pos_class_path) \n",
    "        \n",
    "        for i in range(2): # each batch we choose 2 random instance for each category\n",
    "            # positive\n",
    "            # Choose a random image from pos_class_g\n",
    "            graph_path = self.choose_graph(pos_class_g)\n",
    "            graph = self.read_txt(graph_path)\n",
    "            \n",
    "            # x is 4*512, where each row is the embedding of a node\n",
    "            # y = [1,2,3], target to train against\n",
    "            x = torch.ones((len(graph), 512))  # (4, 512)\n",
    "            for n, vec in enumerate(graph.values()):\n",
    "                x[n] = torch.LongTensor(vec)\n",
    "            y = torch.FloatTensor([label + 1]) # label of each category\n",
    "            \n",
    "            # Construct edge (edge_index representation) (fully connected)\n",
    "            # edge is 2*|E|\n",
    "            source_nodes = []\n",
    "            target_nodes = []\n",
    "            start_choice = [n for n in range(len(graph))] # [0,1,2,3]\n",
    "            for startpt in start_choice:\n",
    "                # do not set loop\n",
    "                end_choice = start_choice.copy()\n",
    "                end_choice.remove(startpt)\n",
    "                for endpt in end_choice:\n",
    "                    source_nodes.append(startpt)\n",
    "                    target_nodes.append(endpt)\n",
    "            edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "            '''edge_feature'''\n",
    "            '''1 edge feature extraction'''\n",
    "            # Each edge has 4 features [xj,yj,xi,yi]\n",
    "            # e_all is 4*4 adjacency matrix\n",
    "            #edge_feature is 4*4*4\n",
    "            edge_path = graph_path.replace('_graph.', '_edge.')\n",
    "            edge_feature = self.read_txt(edge_path)\n",
    "            e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "            for startpt, startpt_values in edge_feature.items():\n",
    "                for endpt, endpt_values in startpt_values.items():\n",
    "                    e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                    \n",
    "            '''2 get edge_feature form edge_index'''\n",
    "            # e is an array of edge features (edge attribute)\n",
    "            # e is |E|*4\n",
    "            e = []\n",
    "            for index, source_p in enumerate(source_nodes):\n",
    "                target_p = target_nodes[index]\n",
    "                e.append(np.array(e_all[source_p][target_p]))\n",
    "            e = torch.Tensor(e)\n",
    "            data = Data(x=x, edge_attr=e, edge_index=edge, y=y)\n",
    "            graph_data_list.append(data)\n",
    "\n",
    "            #  negative (for each class do same thing on remaining classes)\n",
    "            remain_cate = class_list.copy()\n",
    "            remain_cate.remove(cate)\n",
    "            for eij_label, neg_cate in enumerate(remain_cate):\n",
    "                neg_class_path = os.path.join('./result/img2vec/', 'train', neg_cate, cate)\n",
    "                neg_class_g = make_dataset(neg_class_path)\n",
    "                neg_graph_path = self.choose_graph(neg_class_g)\n",
    "                graph = self.read_txt(neg_graph_path)\n",
    "                x = torch.ones((len(graph), 512))  # (3, 512)\n",
    "                for n, vec in enumerate(graph.values()):\n",
    "                    x[n] = torch.LongTensor(vec)\n",
    "                y = torch.FloatTensor([3 + 2 * (label) + (eij_label+1)])  # label of each category (45,67,89)\n",
    "                '''edge_index'''\n",
    "                source_nodes = []\n",
    "                target_nodes = []\n",
    "                start_choice = [n for n in range(len(graph))]\n",
    "                for startpt in start_choice:\n",
    "                    # do not set loop\n",
    "                    end_choice = start_choice.copy()\n",
    "                    end_choice.remove(startpt)\n",
    "                    for endpt in end_choice:\n",
    "                        source_nodes.append(startpt)\n",
    "                        target_nodes.append(endpt)\n",
    "                edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "                '''edge_feature'''\n",
    "                '''1 edge feature extraction'''\n",
    "                edge_path = neg_graph_path.replace('_graph.', '_edge.')\n",
    "                edge_feature = self.read_txt(edge_path)\n",
    "                e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "                for startpt, startpt_values in edge_feature.items():\n",
    "                    for endpt, endpt_values in startpt_values.items():\n",
    "                        e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                '''2 get edge_feature form edge_index'''\n",
    "                e = []\n",
    "                for index, source_p in enumerate(source_nodes):\n",
    "                    target_p = target_nodes[index]\n",
    "                    e.append(np.array(e_all[source_p][target_p]))\n",
    "                e = torch.Tensor(e)\n",
    "                data = Data(x=x, edge_attr=e, edge_index=edge, y=y)\n",
    "                graph_data_list.append(data)\n",
    "\n",
    "    return graph_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d161c-bfd4-4337-8daf-822a9ce93530",
   "metadata": {},
   "source": [
    "Form as graph and store activation value for given class\\\n",
    "similar as previous function but on 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd9c3db-fb28-455b-ac33-42fd0152dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "def _get_1class_XAI(self, cate, label):\n",
    "    class_list = ['fire_engine', 'ambulance', 'school_bus']\n",
    "\n",
    "    graph_data_list = []\n",
    "    XAI_activation_list = []\n",
    "\n",
    "    pos_class_path = os.path.join(self.root, 'img2vec', cate + '_detect_graph')\n",
    "    for roots, dirs, files in os.walk(pos_class_path):\n",
    "        for i, file in enumerate(files):  # we only need limited number for each class\n",
    "            if '_graph' in file: # first process graph\n",
    "                try:\n",
    "                    graph_path = os.path.join(roots,file)\n",
    "                    graph = self.read_txt(graph_path)\n",
    "                    '''x, y'''\n",
    "                    x = torch.ones((len(graph), 2048))  # (4, 2048)\n",
    "                    for n, vec in enumerate(graph.values()):\n",
    "                        x[n] = torch.tensor(vec)\n",
    "                    y = torch.FloatTensor([label + 1]) # label of each category\n",
    "                    '''edge_index'''\n",
    "                    source_nodes = []\n",
    "                    target_nodes = []\n",
    "                    start_choice = [n for n in range(len(graph))]\n",
    "                    for startpt in start_choice:\n",
    "                        # do not set loop\n",
    "                        end_choice = start_choice.copy()\n",
    "                        end_choice.remove(startpt)\n",
    "                        for endpt in end_choice:\n",
    "                            source_nodes.append(startpt)\n",
    "                            target_nodes.append(endpt)\n",
    "                    edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "                    '''edge_feature'''\n",
    "                    '''1 edge feature extraction'''\n",
    "                    edge_path = graph_path.replace('_graph.', '_edge.')\n",
    "                    edge_feature = self.read_txt(edge_path)\n",
    "                    e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "                    for startpt, startpt_values in edge_feature.items():\n",
    "                        for endpt, endpt_values in startpt_values.items():\n",
    "                            e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                    '''2 get edge_feature form edge_index'''\n",
    "                    e = []\n",
    "                    for index, source_p in enumerate(source_nodes):\n",
    "                        target_p = target_nodes[index]\n",
    "                        e.append(np.array(e_all[source_p][target_p]))\n",
    "                    e = torch.Tensor(e)\n",
    "                    '''XAI_activation'''\n",
    "                    act_path = graph_path.replace('_graph.txt', '_XAI.npy')\n",
    "                    act_vector = np.load(act_path)\n",
    "                    # merge the act into y label\n",
    "                    data_pos = Data(x=x, edge_attr=e, edge_index=edge, y=[(y, cate, torch.FloatTensor(act_vector))]) # y is list\n",
    "                    # graph_data_list.append(data)\n",
    "\n",
    "                    #  negative\n",
    "                    remain_cate = class_list.copy()\n",
    "                    remain_cate.remove(cate)\n",
    "                    for eij_label, neg_cate in enumerate(remain_cate): # only load graph, no activation\n",
    "                        neg_cate_file = cate + '2' + neg_cate # e.g. fire_engine2ambulance\n",
    "                        neg_graph_path = graph_path.replace(cate, neg_cate_file)\n",
    "                        graph = self.read_txt(neg_graph_path)\n",
    "                        x = torch.ones((len(graph), 2048))  # (4, 512)\n",
    "                        for n, vec in enumerate(graph.values()):\n",
    "                            # x[n] = torch.LongTensor(vec) # will make all of them 0\n",
    "                            x[n] = torch.tensor(vec)\n",
    "                        y = torch.FloatTensor([label + 1])  # label of each category (45,67,89)\n",
    "                        '''edge_index'''\n",
    "                        source_nodes = []\n",
    "                        target_nodes = []\n",
    "                        start_choice = [n for n in range(len(graph))]\n",
    "                        for startpt in start_choice:\n",
    "                            # do not set loop\n",
    "                            end_choice = start_choice.copy()\n",
    "                            end_choice.remove(startpt)\n",
    "                            for endpt in end_choice:\n",
    "                                source_nodes.append(startpt)\n",
    "                                target_nodes.append(endpt)\n",
    "                        edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "                        '''edge_feature'''\n",
    "                        '''1 edge feature extraction'''\n",
    "                        edge_path = neg_graph_path.replace('_graph.', '_edge.')\n",
    "                        edge_feature = self.read_txt(edge_path)\n",
    "                        e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "                        for startpt, startpt_values in edge_feature.items():\n",
    "                            for endpt, endpt_values in startpt_values.items():\n",
    "                                e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                        '''2 get edge_feature form edge_index'''\n",
    "                        e = []\n",
    "                        for index, source_p in enumerate(source_nodes):\n",
    "                            target_p = target_nodes[index]\n",
    "                            e.append(np.array(e_all[source_p][target_p]))\n",
    "                        e = torch.Tensor(e)\n",
    "                        # '''XAI_activation'''\n",
    "                        data_neg = Data(x=x, edge_attr=e, edge_index=edge, y=(y, neg_cate))\n",
    "                        data_pos.y.append(data_neg) # merge into y\n",
    "                    '''finally add all into data'''\n",
    "                    graph_data_list.append(data_pos)\n",
    "                except:\n",
    "                    print(graph_path)\n",
    "\n",
    "\n",
    "\n",
    "    return graph_data_list, XAI_activation_list  # AXI_activation_list empty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd6634-8749-4370-a56c-a779cef1a637",
   "metadata": {},
   "source": [
    "Processes raw data and saves it into the processed_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913954b1-f09a-4c5e-9a9d-64a1e1b7e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "def process(self):\n",
    "    class_list = ['fire_engine', 'ambulance', 'school_bus']\n",
    "\n",
    "    data_list = [] # store all graphs\n",
    "    XAI_list = []\n",
    "    \"\"\"Yields pair data\"\"\"\n",
    "    pair_labels = [] # 1 or 0\n",
    "    for class_label, target_class in enumerate(class_list):\n",
    "        graph_data_list, XAI_activation_list = self._get_1class_XAI(target_class, class_label)  # get the graphs for this label\n",
    "\n",
    "        '''add pair of data each time'''\n",
    "        data_list += graph_data_list\n",
    "        XAI_list += XAI_activation_list  # XAI_activation_list empty?\n",
    "\n",
    "    #Collates a Python list of torch_geometric.data.Data objects to the internal storage format of InMemoryDataset.\n",
    "    data, slices = self.collate(data_list)\n",
    "    # ava\n",
    "    # torch.save((data, slices, XAI_list), self.processed_paths[0])\n",
    "    torch.save((data, slices, XAI_list), self.processed_file_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0010642-2c7a-4075-8c49-a41093a32c7d",
   "metadata": {},
   "source": [
    "The graph neural network operator from the `\"Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks\" <https://arxiv.org/abs/1810.02244>`_ paper\n",
    "\n",
    "math::\\\n",
    "    $\\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_1 \\mathbf{x}_i +\n",
    "    \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{\\Theta}_2 \\mathbf{x}_j$.\n",
    "\n",
    "Args:\\\n",
    "    in_channels (int or tuple): Size of each input sample. A tuple corresponds to the sizes of source and target dimensionalities.\\\n",
    "    out_channels (int): Size of each output sample.\\\n",
    "    aggr (string, optional): The aggregation scheme to use (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`). (default: :obj:`\"add\"`)\\\n",
    "    bias (bool, optional): If set to :obj:`False`, the layer will not learn an additive bias. (default: :obj:`True`)\\\n",
    "    **kwargs (optional): Additional arguments of class:`torch_geometric.nn.conv.MessagePassing`.\\\n",
    "    \n",
    "Shapes:\\\n",
    "    input:\\\n",
    "      node features $(|\\mathcal{V}|, F_{in})$ or $((|\\mathcal{V_s}|, F_{s})$, $(|\\mathcal{V_t}|, F_{t}))$ if bipartite,\\\n",
    "      edge indices $(2, |\\mathcal{E}|)$,\\\n",
    "      edge weights $(|\\mathcal{E}|)$ (optional)\n",
    "    output:\\\n",
    "    node features $(|\\mathcal{V}|, F_{out})$ or $(|\\mathcal{V}_t|, F_{out})$ if bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb4ede-b41f-45e1-8f80-23101eb3a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(MessagePassing):\n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]], out_channels: int, aggr: str = 'add', bias: bool = True, **kwargs):\n",
    "        super(GraphConv, self).__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        '''fi = W1 * fi + sum(W3* concat(eij * W2 * fj, edge_ij);   edge = W4 * edge'''\n",
    "        self.lin_l = Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
    "        self.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a3850-a334-4de0-b714-c2a5b0b11bc0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390227b2-421e-4ad1-afca-69d353b5d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def reset_parameters(self):\n",
    "    self.lin_l.reset_parameters()\n",
    "    self.lin_r.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1527d8-4253-435b-8a2d-0a992dfe8d57",
   "metadata": {},
   "source": [
    "Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b76d0-2cf3-4284-9904-1c647a6f41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj, edge_weight: OptTensor = None, size: Size = None) -> Tensor:\n",
    "    \"\"\"\"\"\"\n",
    "    if isinstance(x, Tensor):\n",
    "        x: OptPairTensor = (x, x)\n",
    "\n",
    "    # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "    out = self.propagate(edge_index, x=x, edge_weight=edge_weight, size=size)\n",
    "    out = self.lin_l(out)\n",
    "\n",
    "    x_r = x[1]\n",
    "    if x_r is not None:\n",
    "        out += self.lin_r(x_r)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd1266-7c61-43a9-9f55-a24c1795d4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442ecca-9b47-4abb-8831-caa19952deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "    return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad694905-5a0c-4054-961d-6fae8ce935eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d79d44-d292-4d42-9106-d7082a8082bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def __repr__(self):\n",
    "    return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7ca1b-15a7-4988-a63b-c12954aeffae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b68de-f68b-46df-993e-de0291d12bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGCNConv_eij_adap_batch(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, in_edge_features, out_edge_features):\n",
    "        super(MyGCNConv_eij_adap_batch, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin_W1 = torch.nn.Linear(in_channels, out_channels)# W1 for self\n",
    "        self.lin_W2 = torch.nn.Linear(in_channels, out_channels)# W2 for neighbors\n",
    "        self.lin_edge = torch.nn.Linear(in_edge_features, out_edge_features)\n",
    "        self.bn_edge = torch.nn.BatchNorm1d(out_edge_features)\n",
    "        self.lin_message = torch.nn.Linear(out_channels + out_edge_features, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b81614-6d36-4f03-aa1f-9cd2386ece07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46899c-afbe-43a6-b6e4-02b1fe237ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNConv_eij_adap_batch\n",
    "def forward(self, x: Union[Tensor, OptPairTensor], edge_attr, edge_index, eij, batch_size):\n",
    "    # x has shape [N, in_channels]\n",
    "    if isinstance(x, Tensor):\n",
    "        x: OptPairTensor = (x, x)\n",
    "    # edge_index has shape [2, E]\n",
    "    '''fi = W1 * fi + sum(W3* concat(eij * W2 * fj, edge_ij);   edge = W4 * edge'''\n",
    "    # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "\n",
    "    x_j = self.lin_W2(x[0])  # W2 * fj\n",
    "    edge_attr = self.lin_edge(edge_attr) #  W4 * edge\n",
    "    edge_attr =  self.bn_edge(edge_attr)\n",
    "    out = self.propagate(edge_index, x=x_j, edge_weight=eij.repeat(batch_size), edge_attr=edge_attr)\n",
    "\n",
    "    x_i = x[1]\n",
    "    if x_i is not None:\n",
    "        out += self.lin_W1(x_i) # W1 * fi\n",
    "\n",
    "    #  Linearly transform node feature matrix.\n",
    "\n",
    "    return edge_attr, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f7117-58ec-45fa-a391-96b6f90efe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f1d2e1-ebce-4e24-ba2c-f3dcb51dc2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNConv_eij_adap_batch\n",
    "def message(self, x_j, edge_weight, edge_attr):\n",
    "    # x_j has shape [E, out_channels]\n",
    "    # each node prepare some information ready to pass to neighbor based on edge connection\n",
    "    # Step 4: Normalize node features.\n",
    "    # return norm.view(-1, 1) * x_j\n",
    "    after_eij = edge_weight.view(-1, 1) * x_j # use eij first and only on the node feature\n",
    "    all_feature = torch.cat((after_eij, edge_attr), dim=1) # then concate the edgefeature as input\n",
    "    return self.lin_message(all_feature) # W3 * (concat(node, edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776082e-205e-4323-b486-d25d15b99d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b1bf7-6808-4632-9b9c-faa51592b00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGCNNet_shareW_adap_batch(torch.nn.Module):\n",
    "    def __init__(self, dataset, interest_class_num):\n",
    "        super(MyGCNNet_shareW_adap_batch, self).__init__()\n",
    "\n",
    "        num_features = dataset.num_features\n",
    "        dim = 32\n",
    "        edge_features = 4\n",
    "        dim_edge_features = 5\n",
    "        self.output_dim = interest_class_num # one graph only predict corresponding value\n",
    "\n",
    "        '''GCN_eij'''\n",
    "        self.eij_1 = Parameter(torch.Tensor(12))\n",
    "        torch.nn.init.normal(self.eij_1, mean=0, std=1)\n",
    "        self.eij_2 = Parameter(torch.Tensor(12))\n",
    "        torch.nn.init.normal(self.eij_2, mean=0, std=1)\n",
    "        self.eij_3 = Parameter(torch.Tensor(12))\n",
    "        torch.nn.init.normal(self.eij_3, mean=0, std=1)\n",
    "\n",
    "        self.conv1 = MyGCNConv_eij_adap_batch(num_features, dim * 2, edge_features, dim_edge_features)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim * 2) # only do on edge feature\n",
    "\n",
    "        self.conv2 = MyGCNConv_eij_adap_batch(dim * 2, dim, dim_edge_features, dim_edge_features)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.conv3 = MyGCNConv_eij_adap_batch(dim, dim, dim_edge_features, dim_edge_features)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        all_graph_vector_len = 3*(dim * 4 + dim_edge_features * 12)\n",
    "        self.bn6 = torch.nn.BatchNorm1d(all_graph_vector_len) # 564 = 188 * 3\n",
    "        self.fc2 = Linear(all_graph_vector_len, self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608e4df-7355-4e76-8884-d0a4ee241322",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward_1(self, x, edge_attr, edge_index, batch):\n",
    "        '''both x and edge_attr been updated'''\n",
    "        edge_attr, x = self.conv1(x, edge_attr, edge_index, self.eij_1, self.batch_size)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        edge_attr, x = self.conv2(x, edge_attr, edge_index, self.eij_1, self.batch_size)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        edge_attr, x = self.conv3(x, edge_attr, edge_index, self.eij_1, self.batch_size)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        '''add a normalization'''\n",
    "        # x = global_add_pool(x, batch)\n",
    "        '''use concatenete for both x and edge feature'''\n",
    "        # x = x.view(int(batch.max().item() + 1), -1)  # (Num of graph, feature_dim * Num of node) (6, 128)\n",
    "        x = x.view(batch, -1)\n",
    "        edge_attr = edge_attr[0: edge_index.shape[-1]].view(batch, -1)\n",
    "        # edge_attr = f.normalize(edge_attr, p=2, dim=1)\n",
    "        graph_vector = torch.cat((x, edge_attr), dim=1)  # (Num of graph, 128+60)\n",
    "        return graph_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc7a73-3eda-4d6a-92c1-87ca599b8371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f38631-a517-4981-b3aa-89daea82887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward_2(self, x, edge_attr, edge_index, batch):\n",
    "    '''both x and edge_attr been updated'''\n",
    "    edge_attr, x = self.conv1(x, edge_attr, edge_index, self.eij_2, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn1(x)\n",
    "    edge_attr, x = self.conv2(x, edge_attr, edge_index, self.eij_2, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn2(x)\n",
    "    edge_attr, x = self.conv3(x, edge_attr, edge_index, self.eij_2, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn3(x)\n",
    "    '''add a normalization'''\n",
    "    # x = global_add_pool(x, batch)\n",
    "    '''use concatenete for both x and edge feature'''\n",
    "    x = x.view(batch, -1)  # (Num of graph, feature_dim * Num of node) (1, 128)\n",
    "\n",
    "    edge_attr = edge_attr[0: edge_index.shape[-1]].view(batch, -1)\n",
    "    graph_vector = torch.cat((x, edge_attr), dim=1)  # (Num of graph, 128+60)\n",
    "    return graph_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9104c783-8dfb-4fe5-8808-c3910ba2d3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74085b-b55c-4edd-a85c-c9e5fdfa22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward_3(self, x, edge_attr, edge_index, batch):\n",
    "    '''both x and edge_attr been updated'''\n",
    "    edge_attr, x = self.conv1(x, edge_attr, edge_index, self.eij_3, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn1(x)\n",
    "    edge_attr, x = self.conv2(x, edge_attr, edge_index, self.eij_3, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn2(x)\n",
    "    edge_attr, x = self.conv3(x, edge_attr, edge_index, self.eij_3, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn3(x)\n",
    "    '''add a normalization'''\n",
    "    # x = global_add_pool(x, batch)\n",
    "    '''use concatenete for both x and edge feature'''\n",
    "    x = x.view(batch, -1) # (Num of graph, feature_dim * Num of node) (6, 128)\n",
    "\n",
    "    edge_attr = edge_attr[0: edge_index.shape[-1]].view(batch, -1)\n",
    "    graph_vector = torch.cat((x, edge_attr),dim=1) # (Num of graph, 128+60)\n",
    "    return graph_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c99816-1aec-4ed4-b4dc-3e947bd2ba1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c288d6-96f8-4d55-be27-9e8d5b329cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward(self, graph_1, graph_2, graph_3):\n",
    "    all_graph_vector = torch.cat((graph_1, graph_2, graph_3), dim=1)\n",
    "    x = self.fc2(all_graph_vector)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf3a22-fa69-4803-b190-9acf803fc304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec56bde-79d6-4828-b513-a0a0b0c98306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # Create graph input dataset \n",
    "    dataset = VR_graph(root=args.result_root) # this root will not be used\n",
    "    train_dataset = dataset  # total 180000\n",
    "    train_epoch = 1000\n",
    "    batch_size = 128\n",
    "\n",
    "    # Create data loader from dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True) # due to eij switch, batch implement inside\n",
    "    save_root = os.path.join(args.result_root, 'model')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create model \n",
    "    model_share = MyGCNNet_shareW_adap_batch(dataset, interest_class_num=3)  # all class share base structure\n",
    "\n",
    "    '''load pretrain model'''\n",
    "    if args.load_epoch:\n",
    "        save_name = os.path.join(save_root, 'GraphConv_Xception_epoch_{}.pt'.format(args.load_epoch))\n",
    "        model_share.load_state_dict(torch.load(save_name))\n",
    "        ''' load pretrained model'''\n",
    "        print('[Pre] 1 Loaded pretrianed model{}'.format(save_name))\n",
    "\n",
    "    model_share = model_share.to(device)\n",
    "    model_share.batch_size = 1 # fix the batch size\n",
    "\n",
    "    ''' load pretrained model'''\n",
    "    print('[Pre] 1 Loading class-specific model')\n",
    "\n",
    "    optimizer_share = torch.optim.Adam(model_share.parameters(), lr=0.01)\n",
    "    MSE_Loss = torch.nn.MSELoss()\n",
    "\n",
    "    '''store the loss to print'''\n",
    "    loss_log_package = {'all_loss_log': [0], 'inter_loss_log': [0], 'intra_loss_log': [0]}\n",
    "    for epoch in range(1, train_epoch):\n",
    "        '''train_share'''\n",
    "        train_loss, loss_log_package = train_share(epoch, model_share, optimizer_share,\n",
    "                                                   train_dataset, train_loader, batch_size,\n",
    "                                                   MSE_Loss, loss_log_package, device)\n",
    "        print(train_loss)\n",
    "        print('Epoch: {:03d}, Train Loss: {:.7f} '.format(epoch, train_loss))\n",
    "\n",
    "        '''save model'''\n",
    "        if epoch % 20 == 0:\n",
    "            save_name = os.path.join(save_root, 'GraphConv_Xception_epoch_{}.pt'.format(epoch))\n",
    "            torch.save(model_share.state_dict(), os.path.join(save_root, save_name))\n",
    "            print('saved!', epoch)\n",
    "            print('learning rate{}'.format(optimizer_share.param_groups))\n",
    "\n",
    "        '''draw the loss'''\n",
    "        all_loss_log = loss_log_package['all_loss_log']\n",
    "        inter_loss_log = loss_log_package['inter_loss_log']\n",
    "        intra_loss_log = loss_log_package['intra_loss_log']\n",
    "\n",
    "        plot_acc_loss(all_loss_log, inter_loss_log, intra_loss_log, epoch, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
