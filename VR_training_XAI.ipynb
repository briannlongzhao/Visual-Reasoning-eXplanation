{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb43c0e",
   "metadata": {},
   "source": [
    "This script train the graph reasoning algorithm use detected concept for XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97755158",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate VRX\n",
    "import jdc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db109047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from src.image_folder import make_dataset\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "import torch.nn.functional as f\n",
    "from torch.nn import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "from torch_geometric.nn import GraphConv\n",
    "from typing import Union, Tuple\n",
    "from torch_geometric.typing import OptTensor, OptPairTensor, Adj, Size\n",
    "import argparse\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249580d5",
   "metadata": {},
   "source": [
    "create training dataset, InMemoryDataset should be used if the whole dataset fits into CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffe49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VR_graph(InMemoryDataset): \n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        self.root = root\n",
    "        super(VR_graph, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices, self.XAI_act = torch.load(self.processed_file_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea16d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "@property\n",
    "def raw_file_names(self):\n",
    "    return []\n",
    "\n",
    "@property\n",
    "def processed_file_names(self):\n",
    "    return [os.path.join(self.root, 'vec2graph', 'Xception_XAI_graph_training.dataset')]\n",
    "\n",
    "def download(self):\n",
    "        pass\n",
    "'''useful for utils'''\n",
    "\n",
    "def read_txt(self, path):\n",
    "    f = open(path, 'r')\n",
    "    b = f.read()\n",
    "    pos_graph = eval(b)\n",
    "    f.close()\n",
    "    return pos_graph\n",
    "\n",
    "def choose_graph(self, list_mix):\n",
    "    while 1:\n",
    "        pos_graph_path = random.choice(list_mix)\n",
    "        if '_graph.' in pos_graph_path:\n",
    "            return pos_graph_path\n",
    "'''process for contrastive loss'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c7a209",
   "metadata": {},
   "source": [
    "Get graph data list, where graph data is a torch_geometric data reprentation of a graph.\\\n",
    "For each class, generate 2 positive and 4 negative graphs [+1,-1,-1, +1,-1,-1]\n",
    "graph_data_list has 1*18 graph representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6702835",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "def _get_3class_eij(self):\n",
    "    class_list = ['fire_engine', 'ambulance', 'school_bus']\n",
    "    graph_data_list = []\n",
    "    \n",
    "    # for (label=[0,1,2], cate=[class_list])\n",
    "    for label, cate in enumerate(class_list): # 3 category, 6 graph for each class [+1,-1,-1, +1,-1,-1]\n",
    "        \n",
    "        # pos_class_g is an array of paths of training images of a given class\n",
    "        pos_class_path = os.path.join('./result/img2vec/', 'train', cate, cate) # real + eij\n",
    "        pos_class_g = make_dataset(pos_class_path) \n",
    "        \n",
    "        for i in range(2): # each batch we choose 2 random instance for each category\n",
    "            # positive\n",
    "            # Choose a random image from pos_class_g\n",
    "            graph_path = self.choose_graph(pos_class_g)\n",
    "            graph = self.read_txt(graph_path)\n",
    "            \n",
    "            # x is 4*512, where each row is the embedding of a node\n",
    "            # y = [1,2,3], target to train against\n",
    "            x = torch.ones((len(graph), 512))  # (4, 512)\n",
    "            for n, vec in enumerate(graph.values()):\n",
    "                x[n] = torch.LongTensor(vec)\n",
    "            y = torch.FloatTensor([label + 1]) # label of each category\n",
    "            \n",
    "            # Construct edge (edge_index representation) (fully connected)\n",
    "            # edge is 2*|E|\n",
    "            source_nodes = []\n",
    "            target_nodes = []\n",
    "            start_choice = [n for n in range(len(graph))] # [0,1,2,3]\n",
    "            for startpt in start_choice:\n",
    "                # do not set loop\n",
    "                end_choice = start_choice.copy()\n",
    "                end_choice.remove(startpt)\n",
    "                for endpt in end_choice:\n",
    "                    source_nodes.append(startpt)\n",
    "                    target_nodes.append(endpt)\n",
    "            edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "            '''edge_feature'''\n",
    "            '''1 edge feature extraction'''\n",
    "            # Each edge has 4 features [xj,yj,xi,yi]\n",
    "            # e_all is 4*4 adjacency matrix\n",
    "            #edge_feature is 4*4*4\n",
    "            edge_path = graph_path.replace('_graph.', '_edge.')\n",
    "            edge_feature = self.read_txt(edge_path)\n",
    "            e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "            for startpt, startpt_values in edge_feature.items():\n",
    "                for endpt, endpt_values in startpt_values.items():\n",
    "                    e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                    \n",
    "            '''2 get edge_feature form edge_index'''\n",
    "            # e is an array of edge features (edge attribute)\n",
    "            # e is |E|*4\n",
    "            e = []\n",
    "            for index, source_p in enumerate(source_nodes):\n",
    "                target_p = target_nodes[index]\n",
    "                e.append(np.array(e_all[source_p][target_p]))\n",
    "            e = torch.Tensor(e)\n",
    "            data = Data(x=x, edge_attr=e, edge_index=edge, y=y)\n",
    "            graph_data_list.append(data)\n",
    "\n",
    "            #  negative (for each class do same thing on remaining classes)\n",
    "            remain_cate = class_list.copy()\n",
    "            remain_cate.remove(cate)\n",
    "            for eij_label, neg_cate in enumerate(remain_cate):\n",
    "                neg_class_path = os.path.join('./result/img2vec/', 'train', neg_cate, cate)\n",
    "                neg_class_g = make_dataset(neg_class_path)\n",
    "                neg_graph_path = self.choose_graph(neg_class_g)\n",
    "                graph = self.read_txt(neg_graph_path)\n",
    "                x = torch.ones((len(graph), 512))  # (3, 512)\n",
    "                for n, vec in enumerate(graph.values()):\n",
    "                    x[n] = torch.LongTensor(vec)\n",
    "                y = torch.FloatTensor([3 + 2 * (label) + (eij_label+1)])  # label of each category (45,67,89)\n",
    "                '''edge_index'''\n",
    "                source_nodes = []\n",
    "                target_nodes = []\n",
    "                start_choice = [n for n in range(len(graph))]\n",
    "                for startpt in start_choice:\n",
    "                    # do not set loop\n",
    "                    end_choice = start_choice.copy()\n",
    "                    end_choice.remove(startpt)\n",
    "                    for endpt in end_choice:\n",
    "                        source_nodes.append(startpt)\n",
    "                        target_nodes.append(endpt)\n",
    "                edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "                '''edge_feature'''\n",
    "                '''1 edge feature extraction'''\n",
    "                edge_path = neg_graph_path.replace('_graph.', '_edge.')\n",
    "                edge_feature = self.read_txt(edge_path)\n",
    "                e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "                for startpt, startpt_values in edge_feature.items():\n",
    "                    for endpt, endpt_values in startpt_values.items():\n",
    "                        e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                '''2 get edge_feature form edge_index'''\n",
    "                e = []\n",
    "                for index, source_p in enumerate(source_nodes):\n",
    "                    target_p = target_nodes[index]\n",
    "                    e.append(np.array(e_all[source_p][target_p]))\n",
    "                e = torch.Tensor(e)\n",
    "                data = Data(x=x, edge_attr=e, edge_index=edge, y=y)\n",
    "                graph_data_list.append(data)\n",
    "\n",
    "    return graph_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56991d68",
   "metadata": {},
   "source": [
    "Form as graph and store activation value for given class\\\n",
    "similar as previous function but on 1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a777c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "def _get_1class_XAI(self, cate, label):\n",
    "    class_list = ['fire_engine', 'ambulance', 'school_bus']\n",
    "\n",
    "    graph_data_list = []\n",
    "    XAI_activation_list = []\n",
    "\n",
    "    pos_class_path = os.path.join(self.root, 'img2vec', cate + '_detect_graph')\n",
    "    for roots, dirs, files in os.walk(pos_class_path):\n",
    "        for i, file in enumerate(files):  # we only need limited number for each class\n",
    "            if '_graph' in file: # first process graph\n",
    "                try:\n",
    "                    graph_path = os.path.join(roots,file)\n",
    "                    graph = self.read_txt(graph_path)\n",
    "                    '''x, y'''\n",
    "                    x = torch.ones((len(graph), 2048))  # (4, 2048)\n",
    "                    for n, vec in enumerate(graph.values()):\n",
    "                        x[n] = torch.tensor(vec)\n",
    "                    y = torch.FloatTensor([label + 1]) # label of each category\n",
    "                    '''edge_index'''\n",
    "                    source_nodes = []\n",
    "                    target_nodes = []\n",
    "                    start_choice = [n for n in range(len(graph))]\n",
    "                    for startpt in start_choice:\n",
    "                        # do not set loop\n",
    "                        end_choice = start_choice.copy()\n",
    "                        end_choice.remove(startpt)\n",
    "                        for endpt in end_choice:\n",
    "                            source_nodes.append(startpt)\n",
    "                            target_nodes.append(endpt)\n",
    "                    edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "                    '''edge_feature'''\n",
    "                    '''1 edge feature extraction'''\n",
    "                    edge_path = graph_path.replace('_graph.', '_edge.')\n",
    "                    edge_feature = self.read_txt(edge_path)\n",
    "                    e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "                    for startpt, startpt_values in edge_feature.items():\n",
    "                        for endpt, endpt_values in startpt_values.items():\n",
    "                            e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                    '''2 get edge_feature form edge_index'''\n",
    "                    e = []\n",
    "                    for index, source_p in enumerate(source_nodes):\n",
    "                        target_p = target_nodes[index]\n",
    "                        e.append(np.array(e_all[source_p][target_p]))\n",
    "                    e = torch.Tensor(e)\n",
    "                    '''XAI_activation'''\n",
    "                    act_path = graph_path.replace('_graph.txt', '_XAI.npy')\n",
    "                    act_vector = np.load(act_path)\n",
    "                    # merge the act into y label\n",
    "                    data_pos = Data(x=x, edge_attr=e, edge_index=edge, y=[(y, cate, torch.FloatTensor(act_vector))]) # y is list\n",
    "                    # graph_data_list.append(data)\n",
    "\n",
    "                    #  negative\n",
    "                    remain_cate = class_list.copy()\n",
    "                    remain_cate.remove(cate)\n",
    "                    for eij_label, neg_cate in enumerate(remain_cate): # only load graph, no activation\n",
    "                        neg_cate_file = cate + '2' + neg_cate # e.g. fire_engine2ambulance\n",
    "                        neg_graph_path = graph_path.replace(cate, neg_cate_file)\n",
    "                        graph = self.read_txt(neg_graph_path)\n",
    "                        x = torch.ones((len(graph), 2048))  # (4, 512)\n",
    "                        for n, vec in enumerate(graph.values()):\n",
    "                            # x[n] = torch.LongTensor(vec) # will make all of them 0\n",
    "                            x[n] = torch.tensor(vec)\n",
    "                        y = torch.FloatTensor([label + 1])  # label of each category (45,67,89)\n",
    "                        '''edge_index'''\n",
    "                        source_nodes = []\n",
    "                        target_nodes = []\n",
    "                        start_choice = [n for n in range(len(graph))]\n",
    "                        for startpt in start_choice:\n",
    "                            # do not set loop\n",
    "                            end_choice = start_choice.copy()\n",
    "                            end_choice.remove(startpt)\n",
    "                            for endpt in end_choice:\n",
    "                                source_nodes.append(startpt)\n",
    "                                target_nodes.append(endpt)\n",
    "                        edge = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "                        '''edge_feature'''\n",
    "                        '''1 edge feature extraction'''\n",
    "                        edge_path = neg_graph_path.replace('_graph.', '_edge.')\n",
    "                        edge_feature = self.read_txt(edge_path)\n",
    "                        e_all = torch.zeros((len(edge_feature), 4, 4))  # (4, 4, 4)\n",
    "                        for startpt, startpt_values in edge_feature.items():\n",
    "                            for endpt, endpt_values in startpt_values.items():\n",
    "                                e_all[startpt][endpt] = torch.tensor(endpt_values)\n",
    "                        '''2 get edge_feature form edge_index'''\n",
    "                        e = []\n",
    "                        for index, source_p in enumerate(source_nodes):\n",
    "                            target_p = target_nodes[index]\n",
    "                            e.append(np.array(e_all[source_p][target_p]))\n",
    "                        e = torch.Tensor(e)\n",
    "                        # '''XAI_activation'''\n",
    "                        data_neg = Data(x=x, edge_attr=e, edge_index=edge, y=(y, neg_cate))\n",
    "                        data_pos.y.append(data_neg) # merge into y\n",
    "                    '''finally add all into data'''\n",
    "                    graph_data_list.append(data_pos)\n",
    "                except:\n",
    "                    print(graph_path)\n",
    "\n",
    "\n",
    "\n",
    "    return graph_data_list, XAI_activation_list  # AXI_activation_list empty?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8a049d",
   "metadata": {},
   "source": [
    "Processes raw data and saves it into the processed_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69c96dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to VR_graph\n",
    "def process(self):\n",
    "    class_list = ['fire_engine', 'ambulance', 'school_bus']\n",
    "\n",
    "    data_list = [] # store all graphs\n",
    "    XAI_list = []\n",
    "    \"\"\"Yields pair data\"\"\"\n",
    "    pair_labels = [] # 1 or 0\n",
    "    for class_label, target_class in enumerate(class_list):\n",
    "        graph_data_list, XAI_activation_list = self._get_1class_XAI(target_class, class_label)  # get the graphs for this label\n",
    "\n",
    "        '''add pair of data each time'''\n",
    "        data_list += graph_data_list\n",
    "        XAI_list += XAI_activation_list  # XAI_activation_list empty?\n",
    "\n",
    "    #Collates a Python list of torch_geometric.data.Data objects to the internal storage format of InMemoryDataset.\n",
    "    data, slices = self.collate(data_list)\n",
    "    # ava\n",
    "    # torch.save((data, slices, XAI_list), self.processed_paths[0])\n",
    "    torch.save((data, slices, XAI_list), self.processed_file_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269b575",
   "metadata": {},
   "source": [
    "The graph neural network operator from the `\"Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks\" <https://arxiv.org/abs/1810.02244>`_ paper\n",
    "\n",
    "math::\\\n",
    "    $\\mathbf{x}^{\\prime}_i = \\mathbf{\\Theta}_1 \\mathbf{x}_i +\n",
    "    \\sum_{j \\in \\mathcal{N}(i)} \\mathbf{\\Theta}_2 \\mathbf{x}_j$.\n",
    "\n",
    "Args:\\\n",
    "    in_channels (int or tuple): Size of each input sample. A tuple corresponds to the sizes of source and target dimensionalities.\\\n",
    "    out_channels (int): Size of each output sample.\\\n",
    "    aggr (string, optional): The aggregation scheme to use (:obj:`\"add\"`, :obj:`\"mean\"`, :obj:`\"max\"`). (default: :obj:`\"add\"`)\\\n",
    "    bias (bool, optional): If set to :obj:`False`, the layer will not learn an additive bias. (default: :obj:`True`)\\\n",
    "    **kwargs (optional): Additional arguments of class:`torch_geometric.nn.conv.MessagePassing`.\\\n",
    "    \n",
    "Shapes:\\\n",
    "    input:\\\n",
    "      node features $(|\\mathcal{V}|, F_{in})$ or $((|\\mathcal{V_s}|, F_{s})$, $(|\\mathcal{V_t}|, F_{t}))$ if bipartite,\\\n",
    "      edge indices $(2, |\\mathcal{E}|)$,\\\n",
    "      edge weights $(|\\mathcal{E}|)$ (optional)\n",
    "    output:\\\n",
    "    node features $(|\\mathcal{V}|, F_{out})$ or $(|\\mathcal{V}_t|, F_{out})$ if bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edad29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(MessagePassing):\n",
    "    def __init__(self, in_channels: Union[int, Tuple[int, int]], out_channels: int, aggr: str = 'add', bias: bool = True, **kwargs):\n",
    "        super(GraphConv, self).__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "        '''fi = W1 * fi + sum(W3* concat(eij * W2 * fj, edge_ij);   edge = W4 * edge'''\n",
    "        self.lin_l = Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_r = Linear(in_channels[1], out_channels, bias=False)\n",
    "        self.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a25ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc665ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def reset_parameters(self):\n",
    "    self.lin_l.reset_parameters()\n",
    "    self.lin_r.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c7c21",
   "metadata": {},
   "source": [
    "Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj, edge_weight: OptTensor = None, size: Size = None) -> Tensor:\n",
    "    \"\"\"\"\"\"\n",
    "    if isinstance(x, Tensor):\n",
    "        x: OptPairTensor = (x, x)\n",
    "\n",
    "    # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "    out = self.propagate(edge_index, x=x, edge_weight=edge_weight, size=size)\n",
    "    out = self.lin_l(out)\n",
    "\n",
    "    x_r = x[1]\n",
    "    if x_r is not None:\n",
    "        out += self.lin_r(x_r)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0803d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67624c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "    return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2444e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to GraphConv\n",
    "def __repr__(self):\n",
    "    return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0307695d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0656ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGCNConv_eij_adap_batch(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, in_edge_features, out_edge_features):\n",
    "        super(MyGCNConv_eij_adap_batch, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin_W1 = torch.nn.Linear(in_channels, out_channels)# W1 for self\n",
    "        self.lin_W2 = torch.nn.Linear(in_channels, out_channels)# W2 for neighbors\n",
    "        self.lin_edge = torch.nn.Linear(in_edge_features, out_edge_features)\n",
    "        self.bn_edge = torch.nn.BatchNorm1d(out_edge_features)\n",
    "        self.lin_message = torch.nn.Linear(out_channels + out_edge_features, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6bf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNConv_eij_adap_batch\n",
    "def forward(self, x: Union[Tensor, OptPairTensor], edge_attr, edge_index, eij, batch_size):\n",
    "    # x has shape [N, in_channels]\n",
    "    if isinstance(x, Tensor):\n",
    "        x: OptPairTensor = (x, x)\n",
    "    # edge_index has shape [2, E]\n",
    "    '''fi = W1 * fi + sum(W3* concat(eij * W2 * fj, edge_ij);   edge = W4 * edge'''\n",
    "    # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "\n",
    "    x_j = self.lin_W2(x[0])  # W2 * fj\n",
    "    edge_attr = self.lin_edge(edge_attr) #  W4 * edge\n",
    "    edge_attr =  self.bn_edge(edge_attr)\n",
    "    out = self.propagate(edge_index, x=x_j, edge_weight=eij.repeat(batch_size), edge_attr=edge_attr)\n",
    "\n",
    "    x_i = x[1]\n",
    "    if x_i is not None:\n",
    "        out += self.lin_W1(x_i) # W1 * fi\n",
    "\n",
    "    #  Linearly transform node feature matrix.\n",
    "\n",
    "    return edge_attr, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63092e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNConv_eij_adap_batch\n",
    "def message(self, x_j, edge_weight, edge_attr):\n",
    "    # x_j has shape [E, out_channels]\n",
    "    # each node prepare some information ready to pass to neighbor based on edge connection\n",
    "    # Step 4: Normalize node features.\n",
    "    # return norm.view(-1, 1) * x_j\n",
    "    after_eij = edge_weight.view(-1, 1) * x_j # use eij first and only on the node feature\n",
    "    all_feature = torch.cat((after_eij, edge_attr), dim=1) # then concate the edgefeature as input\n",
    "    return self.lin_message(all_feature) # W3 * (concat(node, edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4edf002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d6b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGCNNet_shareW_adap_batch(torch.nn.Module):\n",
    "    def __init__(self, dataset, interest_class_num):\n",
    "        super(MyGCNNet_shareW_adap_batch, self).__init__()\n",
    "\n",
    "        num_features = dataset.num_features\n",
    "        dim = 32\n",
    "        edge_features = 4\n",
    "        dim_edge_features = 5\n",
    "        self.output_dim = interest_class_num # one graph only predict corresponding value\n",
    "\n",
    "        '''GCN_eij'''\n",
    "        self.eij_1 = Parameter(torch.Tensor(12))\n",
    "        torch.nn.init.normal(self.eij_1, mean=0, std=1)\n",
    "        self.eij_2 = Parameter(torch.Tensor(12))\n",
    "        torch.nn.init.normal(self.eij_2, mean=0, std=1)\n",
    "        self.eij_3 = Parameter(torch.Tensor(12))\n",
    "        torch.nn.init.normal(self.eij_3, mean=0, std=1)\n",
    "\n",
    "        self.conv1 = MyGCNConv_eij_adap_batch(num_features, dim * 2, edge_features, dim_edge_features)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim * 2) # only do on edge feature\n",
    "\n",
    "        self.conv2 = MyGCNConv_eij_adap_batch(dim * 2, dim, dim_edge_features, dim_edge_features)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.conv3 = MyGCNConv_eij_adap_batch(dim, dim, dim_edge_features, dim_edge_features)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        all_graph_vector_len = 3*(dim * 4 + dim_edge_features * 12)\n",
    "        self.bn6 = torch.nn.BatchNorm1d(all_graph_vector_len) # 564 = 188 * 3\n",
    "        self.fc2 = Linear(all_graph_vector_len, self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb20cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward_1(self, x, edge_attr, edge_index, batch):\n",
    "        '''both x and edge_attr been updated'''\n",
    "        edge_attr, x = self.conv1(x, edge_attr, edge_index, self.eij_1, self.batch_size)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        edge_attr, x = self.conv2(x, edge_attr, edge_index, self.eij_1, self.batch_size)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        edge_attr, x = self.conv3(x, edge_attr, edge_index, self.eij_1, self.batch_size)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        '''add a normalization'''\n",
    "        # x = global_add_pool(x, batch)\n",
    "        '''use concatenete for both x and edge feature'''\n",
    "        # x = x.view(int(batch.max().item() + 1), -1)  # (Num of graph, feature_dim * Num of node) (6, 128)\n",
    "        x = x.view(batch, -1)\n",
    "        edge_attr = edge_attr[0: edge_index.shape[-1]].view(batch, -1)\n",
    "        # edge_attr = f.normalize(edge_attr, p=2, dim=1)\n",
    "        graph_vector = torch.cat((x, edge_attr), dim=1)  # (Num of graph, 128+60)\n",
    "        return graph_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840669fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward_2(self, x, edge_attr, edge_index, batch):\n",
    "    '''both x and edge_attr been updated'''\n",
    "    edge_attr, x = self.conv1(x, edge_attr, edge_index, self.eij_2, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn1(x)\n",
    "    edge_attr, x = self.conv2(x, edge_attr, edge_index, self.eij_2, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn2(x)\n",
    "    edge_attr, x = self.conv3(x, edge_attr, edge_index, self.eij_2, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn3(x)\n",
    "    '''add a normalization'''\n",
    "    # x = global_add_pool(x, batch)\n",
    "    '''use concatenete for both x and edge feature'''\n",
    "    x = x.view(batch, -1)  # (Num of graph, feature_dim * Num of node) (1, 128)\n",
    "\n",
    "    edge_attr = edge_attr[0: edge_index.shape[-1]].view(batch, -1)\n",
    "    graph_vector = torch.cat((x, edge_attr), dim=1)  # (Num of graph, 128+60)\n",
    "    return graph_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430cf759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward_3(self, x, edge_attr, edge_index, batch):\n",
    "    '''both x and edge_attr been updated'''\n",
    "    edge_attr, x = self.conv1(x, edge_attr, edge_index, self.eij_3, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn1(x)\n",
    "    edge_attr, x = self.conv2(x, edge_attr, edge_index, self.eij_3, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn2(x)\n",
    "    edge_attr, x = self.conv3(x, edge_attr, edge_index, self.eij_3, self.batch_size)\n",
    "    x = F.relu(x)\n",
    "    x = self.bn3(x)\n",
    "    '''add a normalization'''\n",
    "    # x = global_add_pool(x, batch)\n",
    "    '''use concatenete for both x and edge feature'''\n",
    "    x = x.view(batch, -1) # (Num of graph, feature_dim * Num of node) (6, 128)\n",
    "\n",
    "    edge_attr = edge_attr[0: edge_index.shape[-1]].view(batch, -1)\n",
    "    graph_vector = torch.cat((x, edge_attr),dim=1) # (Num of graph, 128+60)\n",
    "    return graph_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215439f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to MyGCNNet_shareW_adap_batch\n",
    "def forward(self, graph_1, graph_2, graph_3):\n",
    "    all_graph_vector = torch.cat((graph_1, graph_2, graph_3), dim=1)\n",
    "    x = self.fc2(all_graph_vector)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf0d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # Create graph input dataset \n",
    "    dataset = VR_graph(root=args.result_root) # this root will not be used\n",
    "    train_dataset = dataset  # total 180000\n",
    "    train_epoch = 1000\n",
    "    batch_size = 128\n",
    "\n",
    "    # Create data loader from dataset\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True) # due to eij switch, batch implement inside\n",
    "    save_root = os.path.join(args.result_root, 'model')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create model \n",
    "    model_share = MyGCNNet_shareW_adap_batch(dataset, interest_class_num=3)  # all class share base structure\n",
    "\n",
    "    '''load pretrain model'''\n",
    "    if args.load_epoch:\n",
    "        save_name = os.path.join(save_root, 'GraphConv_Xception_epoch_{}.pt'.format(args.load_epoch))\n",
    "        model_share.load_state_dict(torch.load(save_name))\n",
    "        ''' load pretrained model'''\n",
    "        print('[Pre] 1 Loaded pretrianed model{}'.format(save_name))\n",
    "\n",
    "    model_share = model_share.to(device)\n",
    "    model_share.batch_size = 1 # fix the batch size\n",
    "\n",
    "    ''' load pretrained model'''\n",
    "    print('[Pre] 1 Loading class-specific model')\n",
    "\n",
    "    optimizer_share = torch.optim.Adam(model_share.parameters(), lr=0.01)\n",
    "    MSE_Loss = torch.nn.MSELoss()\n",
    "\n",
    "    '''store the loss to print'''\n",
    "    loss_log_package = {'all_loss_log': [0], 'inter_loss_log': [0], 'intra_loss_log': [0]}\n",
    "    for epoch in range(1, train_epoch):\n",
    "        '''train_share'''\n",
    "        train_loss, loss_log_package = train_share(epoch, model_share, optimizer_share,\n",
    "                                                   train_dataset, train_loader, batch_size,\n",
    "                                                   MSE_Loss, loss_log_package, device)\n",
    "        print(train_loss)\n",
    "        print('Epoch: {:03d}, Train Loss: {:.7f} '.format(epoch, train_loss))\n",
    "\n",
    "        '''save model'''\n",
    "        if epoch % 20 == 0:\n",
    "            save_name = os.path.join(save_root, 'GraphConv_Xception_epoch_{}.pt'.format(epoch))\n",
    "            torch.save(model_share.state_dict(), os.path.join(save_root, save_name))\n",
    "            print('saved!', epoch)\n",
    "            print('learning rate{}'.format(optimizer_share.param_groups))\n",
    "\n",
    "        '''draw the loss'''\n",
    "        all_loss_log = loss_log_package['all_loss_log']\n",
    "        inter_loss_log = loss_log_package['inter_loss_log']\n",
    "        intra_loss_log = loss_log_package['intra_loss_log']\n",
    "\n",
    "        plot_acc_loss(all_loss_log, inter_loss_log, intra_loss_log, epoch, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
